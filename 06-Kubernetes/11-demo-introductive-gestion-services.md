---
title: "Chapitre 11 - d√©monstration introductive de la gestion des services (pratique8)"
description: "Projet final qui combine tous les concepts appris pour d√©ployer automatiquement une infrastructure web compl√®te avec base de donn√©es"
emoji: "üîß"
---

# Chapitre 11 - d√©monstration introductive de la gestion des services (pratique8) 

---
<a name="table-des-mati√®res"></a>
## Table des mati√®res


# Les Services en d√©tail partie02

# 1 - Introduction

Les Services dans Kubernetes permettent de communiquer avec un ou plusieurs Pods. Habituellement, les Pods sont √©ph√©m√®res et peuvent changer fr√©quemment d'adresse IP. Les Services fournissent une adresse IP fixe et un nom DNS pour un ensemble de Pods, et chargent √©galement la balance du trafic vers ces Pods.

# R√©f√©rence tr√®s importante:

- https://www.youtube.com/watch?v=5lzUpDtmWgM
  
# 2 - Pr√©requis

- Avoir install√© `kubectl`.
- Avoir acc√®s √† un cluster Kubernetes.
- Avoir fait le lab pr√©c√©dent 03-Gestion-des-deploiments et avoir cr√©e 1 d√©ploiement nginx avec 3 pods avec cette section
```yaml
  template:
    metadata:
      labels:
        app: nginx
  ```
- Avoir regard√© la vid√©o sur les services de type nodePort :

##  https://www.youtube.com/watch?v=5lzUpDtmWgM 

# 3 - √âtape 1: Cr√©ation du fichier YAML pour le Service

Pour exposer le d√©ploiement `nginx` cr√©√© pr√©c√©demment, nous utiliserons un Service de type `NodePort` qui rendra l'application accessible de l'ext√©rieur du cluster Kubernetes.

1. **Ouvrez votre √©diteur de texte ou IDE**.
2. **Cr√©ez un fichier nomm√©** `myservice.yaml`.
3. **Ajoutez le contenu suivant au fichier** :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30008
```


- particuli√®rement, cette section est importante 
```yaml
spec:
  type: NodePort
  selector:
    app: nginx
```
puisque nous allons communiquer avec les pods qui ont cette section
```yaml
  template:
    metadata:
      labels:
        app: nginx
```
- En effet, rappelez vous que dans la pratique pr√©c√©dente, nous avons cr√©e ce d√©ploiement

*mydeployment.yaml*
```ssh
kubect apply -f mydeployment.yaml
```

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
```



# 4- √âtape 2: D√©ploiement du Service

D√©ployez le Service dans votre cluster Kubernetes pour exposer le d√©ploiement `nginx`.

- **Ouvrez un terminal**.
- **Naviguez au r√©pertoire contenant** `myservice.yaml`.
- **Ex√©cutez la commande** pour cr√©er le Service :

```bash
kubectl apply -f myservice.yaml
```

# 5- √âtape 3: V√©rification du Service

Apr√®s avoir cr√©√© le Service, v√©rifiez qu'il est correctement configur√© et qu'il route le trafic vers votre Pod `nginx`.

- **Pour obtenir des informations sur le Service, ex√©cutez** :

```bash
kubectl get services
```

- **Pour obtenir des d√©tails plus sp√©cifiques sur le Service 'nginx-service', utilisez** :

```bash
kubectl describe service nginx-service
```


```bash
minikube ip
curl IP: 30008

```

# 6 - Conclusion

Les Services sont essentiels pour la gestion du trafic r√©seau dans les applications Kubernetes, fournissant un point d'acc√®s stable aux applications dynamiques. Ce tutoriel vous a guid√© √† travers la cr√©ation d'un Service qui expose un d√©ploiement Nginx dans un cluster Kubernetes.

# 7 - R√©sum√© des Commandes (IGNOREZ - ANCIEN)

```bash
# Cr√©er le fichier YAML pour le Service
echo "
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
" > myservice.yaml

# D√©ployer le Service
kubectl apply -f myservice.yaml

# Lister les services pour v√©rifier l'√©tat
kubectl get services

# Obtenir des d√©tails sur le service 'nginx-service'
kubectl describe service nginx-service
```

Ce guide fournit une introduction pratique √† la gestion des services dans Kubernetes, ce qui est crucial pour la production et la gestion efficace des applications.

# Annexe : 

![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/959df9b2-5064-49db-b27a-b92ae8591b2e)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/0af95945-6f87-435c-9fad-3cec7288a35c)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/65cce007-a223-4a66-a2e6-01389aea3b50)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/bf3a4624-f086-4af3-b289-e4af1841f5a9)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/127521c5-20fd-4d27-bfbe-d4ae97b7e585)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/57c0cadc-28c0-467b-98e4-65b77d4d9ca0)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/c74ac877-d536-4eeb-b7ab-c52e50476195)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/23c3e6f6-a79e-487c-abb5-baa8b81dd7a3)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/531ddaca-a64f-4c77-bc57-74df11038e8b)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/bcefc328-4e96-4169-829c-9b197a9c98ca)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/766e4314-bb5a-48e9-8880-193ec32b48c0)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/5dee1237-56bd-4393-8e63-58d4ac6b8ee0)
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/be8e2ca9-b589-4769-b342-d686d9d692da)

# Cas de plusieurs noeuds
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/8cfb853a-9991-44b0-9b14-5e36bbc3a30a)



### Partie 1 : Introduction aux Services Kubernetes

- Dans cette partie, nous allons discuter des services Kubernetes.

- Les services Kubernetes permettent la communication entre les diff√©rentes composantes de l'application, qu'elles soient internes ou externes.

- *Les services Kubernetes nous aident √† connecter des applications entre elles ou avec des utilisateurs.*

- Par exemple, notre application pourrait avoir plusieurs groupes de composants ex√©cutant diff√©rentes sections : un groupe pour servir une interface utilisateur, un autre groupe pour les processus backend, et un troisi√®me groupe pour se connecter √† une source de donn√©es externe.

-*Ce sont les services qui permettent la connectivit√© entre ces groupes de composants.*

- **Les services rendent l'application frontale accessible aux utilisateurs finaux, facilitent la communication entre les composants backend et frontend, et permettent la connexion √† une source de donn√©es externe.**

![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/959df9b2-5064-49db-b27a-b92ae8591b2e)

- Ainsi, les services permettent un couplage l√¢che entre les microservices de notre application.


### Utilisation des Services

- Voyons un cas concret de l'utilisation des services.

- Jusqu'√† pr√©sent, nous avons parl√© de la communication entre les pods via le r√©seau interne.

- Examinons maintenant d'autres aspects du r√©seau dans cette le√ßon.

### Communication Externe

- Imaginons que nous ayons d√©ploy√© notre pod avec une application web qui y tourne. Comment, en tant qu'utilisateur externe, pouvons-nous acc√©der √† cette page web ?

#### Configuration Existante

- Le n≈ìud Kubernetes a une adresse IP, par exemple 192.168.1.2. Mon ordinateur portable est sur le m√™me r√©seau avec l'adresse IP 192.168.1.10. Le r√©seau interne des pods est dans la plage 10.240.0.0, et le pod a une adresse IP 10.240.0.2.

- Il est clair que je ne peux pas pinger ou acc√©der directement au pod √† l'adresse 10.240.0.2 car il se trouve sur un r√©seau s√©par√©.
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/0af95945-6f87-435c-9fad-3cec7288a35c)

## Solution: 
![image](https://github.com/hrhouma/beginingKubernetes-part2/assets/10111526/65cce007-a223-4a66-a2e6-01389aea3b50)

#### Options pour Voir la Page Web

- Premi√®rement, si nous nous connectons au n≈ìud Kubernetes √† l'adresse 192.168.1.2, depuis ce n≈ìud, nous pourrions acc√©der √† la page web du pod en utilisant une commande curl ou en ouvrant un navigateur et en acc√©dant √† l'adresse http://10.240.0.2.

- Cependant, cela se fait depuis l'int√©rieur du n≈ìud Kubernetes, et ce n'est pas ce que nous voulons. Nous souhaitons acc√©der au serveur web depuis notre propre ordinateur sans avoir √† nous connecter au n≈ìud, simplement en acc√©dant √† l'IP du n≈ìud Kubernetes.

- Nous avons donc besoin de quelque chose pour mapper les requ√™tes de notre ordinateur au n≈ìud, puis du n≈ìud au pod ex√©cutant le conteneur web. C'est l√† qu'interviennent les services Kubernetes.

### Types de Services Kubernetes

Le service Kubernetes est un objet, tout comme les pods, les r√©plicasets ou les d√©ploiements que nous avons utilis√©s auparavant. Un de ses cas d'utilisation est d'√©couter un port sur le n≈ìud et de transf√©rer les requ√™tes de ce port √† un port sur le pod ex√©cutant l'application web.

#### NodePort

- Ce type de service est appel√© NodePort, car le service √©coute un port sur le n≈ìud et transf√®re les requ√™tes √† ce port.

#### ClusterIP

- Le deuxi√®me type de service est le ClusterIP. Dans ce cas, le service cr√©e une IP virtuelle √† l'int√©rieur du cluster pour permettre la communication entre diff√©rents services, comme un ensemble de serveurs frontend et un ensemble de serveurs backend.

#### LoadBalancer

- Le troisi√®me type est le LoadBalancer, o√π il provisionne un √©quilibrage de charge pour notre application sur des fournisseurs de cloud support√©s, comme pour distribuer la charge entre diff√©rents serveurs web dans la couche frontend.

### Cr√©ation d'un Service NodePort

- Revenons √† NodePort, nous avons discut√© de l'acc√®s externe √† l'application. Nous avons dit qu'un service peut nous aider en mappant un port sur le n≈ìud √† un port sur le pod.

- Regardons de plus pr√®s le service. Il y a trois ports impliqu√©s :

1. Le port sur le pod o√π le serveur web s'ex√©cute, appel√© port cible (target port), g√©n√©ralement 80.
2. Le port sur le service lui-m√™me, simplement appel√© port.
3. Le port sur le n≈ìud, appel√© NodePort, par exemple 30008.

- Nous cr√©ons un service en utilisant un fichier de d√©finition, comme nous l'avons fait pour les d√©ploiements, les r√©plicasets ou les pods. La structure du fichier reste la m√™me : API version, kind, metadata et spec.

- La version de l'API est v1.
- Le kind est Service.
- Les metadata incluent le nom du service.
- La section spec est cruciale : on y d√©finit les ports et le type de service (NodePort).

## Sous ports, nous d√©finissons :
- Le port cible (target port), 80.
- Le port du service, 80.
- Le NodePort, par exemple 30008.

- Il manque encore une chose : connecter le service au pod. Nous utilisons des labels et des s√©lecteurs pour cela. Nous ajoutons les labels du pod dans la section selector du fichier de d√©finition du service.

- Une fois cela fait, nous cr√©ons le service avec la commande `kubectl create` et v√©rifions avec `kubectl get services`.

### Acc√®s au Service

- Nous pouvons maintenant acc√©der au service web en utilisant curl ou un navigateur avec l'adresse IP du n≈ìud et le NodePort.

- Pour r√©sumer, que ce soit un pod unique, plusieurs pods sur un m√™me n≈ìud, ou plusieurs pods sur plusieurs n≈ìuds, le service est cr√©√© de la m√™me mani√®re sans √©tapes suppl√©mentaires.



# Partie 2 : D√©monstration des Services Kubernetes

Dans cette d√©monstration, nous allons examiner les services dans Kubernetes et reprendre l√† o√π nous nous √©tions arr√™t√©s lors de la pr√©c√©dente d√©monstration.

Nous avons cr√©√© quelques pods en cr√©ant un d√©ploiement, alors v√©rifions d'abord le statut de ce d√©ploiement.

Nous avons un d√©ploiement appel√© "my-app-deployment" avec six r√©plicas, ce qui signifie essentiellement que six pods fonctionnent dans le cluster Kubernetes.

Nous avons maintenant une application cr√©√©e pour s'ex√©cuter sur ce cluster. Cependant, pour que l'utilisateur final puisse y acc√©der via son navigateur web, nous devons cr√©er un service.

Pour ce faire, revenons √† notre √©diteur.

Nous avons cr√©√© un nouveau r√©pertoire appel√© "Service". Dans ce r√©pertoire "Service", nous allons cr√©er un nouveau fichier appel√© "service-definition.yaml".

Notez que vous n'avez pas besoin de suivre cette structure de r√©pertoire comme je le fais. Je le fais simplement pour organiser les exemples. Vous pourriez simplement avoir tous les fichiers au m√™me endroit.

### Cr√©ation du Fichier de D√©finition du Service

Comme pr√©c√©demment, la premi√®re chose √† ajouter est l'√©l√©ment racine, la version de l'API. Pour un service, elle doit √™tre d√©finie √† "v1". Pour le type (kind), nous allons sp√©cifier "Service".

Ensuite, nous allons ajouter les m√©tadonn√©es avec le nom du service que nous pouvons appeler "my-app-service".

Sous cela, nous allons ajouter la section des sp√©cifications (spec). La premi√®re propri√©t√© que nous allons cr√©er est le type de service, que nous allons d√©finir comme "NodePort".

Notre objectif est de pouvoir acc√©der √† notre application sur un port du n≈ìud, qui est le n≈ìud Minikube dans notre cas.

Nous allons ensuite ajouter le port et le port par d√©faut sur lequel Nginx √©coute, qui est 80. Nous allons √©galement ajouter notre port cible (target port), qui est √©galement le port 80.

Il s'agit essentiellement du port sur le service lui-m√™me.

Ensuite, nous allons ajouter un NodePort que nous pouvons d√©finir √† une valeur telle que 30004. Cela pourrait √™tre n'importe quelle valeur entre 30000 et 32767.

Ce NodePort est le port sur le n≈ìud, le n≈ìud de travail, qui est le n≈ìud Minikube sur lequel l'application sera accessible.

Ensuite, nous allons ajouter un s√©lecteur (selector) qui nous aide √† lier notre service au pod avec la m√™me √©tiquette.

### V√©rification du Fichier de D√©ploiement

Jetons rapidement un coup d'≈ìil au fichier YAML de d√©ploiement et vous remarquerez que l'√©tiquette pour le pod est "app" avec la valeur "my-app".

Ajoutons cette m√™me valeur ici sous la section "selector".

### Finalisation du Fichier de D√©finition du Service

Une fois cela termin√©, notre fichier de d√©finition de service est complet et nous pouvons proc√©der √† sa cr√©ation sur nos clusters.

Je vais le sauvegarder ici et revenir √† mon terminal. Je vais naviguer vers le nouveau r√©pertoire que nous avons cr√©√©, o√π se trouve notre fichier de d√©finition de service.

Je vais cr√©er le service en utilisant la commande `kubectl create` avec l'option `-f` et sp√©cifier le fichier de d√©finition du service en entr√©e.

Je lance cette commande et le service a √©t√© cr√©√©.

Nous pouvons maintenant ex√©cuter la commande `kubectl get services` et vous remarquerez que le nouveau service est visible. Le type du service est "NodePort", car nous voulons qu'il soit accessible sur le port du n≈ìud de travail.

Voici l'adresse IP du cluster qui est √©galement cr√©√©e pour le service. Il s'agit d'une adresse cr√©√©e pour le service dans le r√©seau interne du cluster.

Voici le port sur le n≈ìud de travail que nous pouvons utiliser pour acc√©der √† notre application. Si vous connaissez l'adresse IP du n≈ìud de travail, vous pouvez simplement aller sur un navigateur, taper l'adresse IP du n≈ìud de travail suivie du num√©ro de port, et vous devriez pouvoir acc√©der √† cette application.

### Utilisation de Minikube

Comme nous ex√©cutons cela sur Minikube, nous pouvons √©galement utiliser la commande `minikube service` suivie du nom du service, qui est "my-app-service", et utiliser l'option `--url`. Cela devrait nous donner l'URL o√π le service est disponible.

Essayons d'acc√©der √† cela sur un navigateur. Vous pouvez simplement copier cette URL, aller sur un navigateur et coller cette URL dans le navigateur. Nous voyons alors la page web par d√©faut de Nginx, ce qui confirme que l'application Nginx est op√©rationnelle et accessible via un navigateur web.

C'est tout pour cette d√©monstration. Je vous retrouverai dans la prochaine le√ßon.

### Partie 3 : ClusterIP

Bonjour et bienvenue dans ce cours.

Dans cette le√ßon, nous allons discuter du service ClusterIP de Kubernetes.

Une application web full-stack a g√©n√©ralement diff√©rents types de pods h√©bergeant diff√©rentes parties de l'application.

Vous pouvez avoir plusieurs pods ex√©cutant un serveur web frontend, un autre ensemble de pods ex√©cutant un serveur backend, un ensemble de pods ex√©cutant un store cl√©-valeur comme Redis et un autre ensemble de pods ex√©cutant une base de donn√©es persistante comme MySQL.

Le serveur web frontend doit communiquer avec les serveurs backend, et ces derniers doivent communiquer avec la base de donn√©es ainsi que les services Redis, etc.

### Connectivit√© entre les Services

Les pods ont tous une adresse IP qui leur est attribu√©e, comme nous pouvons le voir √† l'√©cran. Cependant, ces adresses IP ne sont pas statiques. Les pods peuvent tomber √† tout moment et de nouveaux pods sont cr√©√©s en permanence, donc vous ne pouvez pas vous fier √† ces adresses IP pour la communication interne entre les composants de l'application.

De plus, si le premier pod frontend √† l'adresse 10.240.0.3 doit se connecter √† un service backend, lequel des trois doit-il choisir et qui prend cette d√©cision ?

Un service Kubernetes peut nous aider √† regrouper les pods et √† fournir une interface unique pour acc√©der aux pods d'un groupe.

### Exemple de Service Backend

Par exemple, un service cr√©√© pour les pods backend regroupera tous les pods backend et fournira une interface unique pour que d'autres pods puissent acc√©der √† ce service. Les requ√™tes sont transf√©r√©es de mani√®re al√©atoire √† l'un des pods sous le service.

De m√™me, vous pouvez cr√©er des services suppl√©mentaires pour Redis et permettre aux pods backend d'acc√©der aux syst√®mes Redis via le service. Cela nous permet de d√©ployer facilement et efficacement une application bas√©e sur des microservices sur un cluster Kubernetes.

Chaque couche peut maintenant s'adapter ou se d√©placer selon les besoins sans impacter la communication entre les diff√©rents services.

### Cr√©ation d'un Service ClusterIP

Chaque service obtient une IP et un nom attribu√©s √† l'int√©rieur du cluster, et c'est ce nom qui doit √™tre utilis√© par les autres pods pour acc√©der au service. Ce type de service est connu sous le nom de ClusterIP.

Pour cr√©er un tel service, utilisez comme toujours un fichier de d√©finition. Dans ce fichier de d√©finition de service, utilisez le mod√®le par d√©faut avec les sections API version, kind, metadata et spec.

- La version de l'API est "v1".
- Le type est "Service".
- Donnez un nom √† votre service, par exemple "backend".

Sous la sp√©cification, nous avons le type et les ports. Le type est ClusterIP. En fait, ClusterIP est le type par d√©faut, donc m√™me si vous ne le sp√©cifiez pas, il assumera automatiquement ce type.

Sous la section ports, nous avons le targetPort et le port. Le targetPort est le port o√π le backend est expos√©, dans ce cas 80, et le port est celui o√π le service est expos√©, qui est √©galement 80.

Pour lier le service √† un ensemble de pods, nous utilisons un s√©lecteur. Nous r√©f√©rons au fichier de d√©finition des pods, copions les labels de celui-ci et les pla√ßons sous la section selector.

### Cr√©ation et V√©rification du Service

- Nous pouvons maintenant cr√©er le service en utilisant la commande `kubectl create` et v√©rifier son statut avec la commande `kubectl get services`.
- Le service peut √™tre accessible par d'autres pods en utilisant le ClusterIP ou le nom du service.



### Partie 4 : LoadBalancer

- Nous allons maintenant examiner un autre type de service connu sous le nom de LoadBalancer.

- Nous avons d√©j√† vu le service NodePort qui nous permet de rendre une application externe accessible sur un port des n≈ìuds de travail. Concentrons-nous maintenant sur les applications frontend, comme l'application de vote et l'application de r√©sultats.

- Ces pods sont h√©berg√©s sur les n≈ìuds de travail dans un cluster. Supposons que nous ayons un cluster de quatre n≈ìuds et que nous voulions rendre les applications accessibles aux utilisateurs externes en cr√©ant des services de type NodePort.

### Accessibilit√© avec NodePort

- Les services de type NodePort permettent de recevoir le trafic sur les ports des n≈ìuds et de le rediriger vers les pods respectifs. Mais quelle URL donneriez-vous √† vos utilisateurs pour acc√©der aux applications ?

- Vous pourriez acc√©der √† n'importe laquelle de ces deux applications en utilisant l'IP de n'importe lequel des n≈ìuds et le port √©lev√© sur lequel le service est expos√©. Cela signifie que vous auriez quatre combinaisons d'IP et de port pour l'application de vote et quatre combinaisons d'IP et de port pour l'application de r√©sultats.

- M√™me si vos pods sont uniquement h√©berg√©s sur deux des n≈ìuds, ils seront toujours accessibles via les IP de tous les n≈ìuds du cluster. Par exemple, si les pods de l'application de vote ne sont d√©ploy√©s que sur les n≈ìuds avec les IP 70 et 71, ils seront toujours accessibles sur les ports de tous les n≈ìuds du cluster.

### Besoin d'une URL Unique

- Pourtant, ce n'est pas ce que les utilisateurs finaux souhaitent. Ils ont besoin d'une URL unique, comme par exemple `voting.abc.com` ou `result.abc.com`, pour acc√©der √† l'application. Comment y parvenir ?
  
- Une fa√ßon d'y parvenir est de cr√©er une nouvelle machine virtuelle pour le load balancer, d'y installer et de configurer un load balancer appropri√© comme HAProxy ou NGINX, puis de configurer le load balancer pour rediriger le trafic vers les n≈ìuds sous-jacents.

### Utilisation des Load Balancers Natifs des Clouds

- Cependant, configurer tout cela et ensuite maintenir et g√©rer le load balancer externe peut √™tre une t√¢che fastidieuse. Si nous √©tions sur une plateforme cloud support√©e comme Google Cloud, AWS ou Azure, nous pourrions tirer parti du load balancer natif de cette plateforme cloud.

- Kubernetes prend en charge l'int√©gration avec les load balancers natifs de certains fournisseurs de cloud et peut configurer cela pour nous. Il suffit de d√©finir le type de service pour les services frontend en tant que LoadBalancer au lieu de NodePort.

### Environnements Support√©s

- Il est important de noter que cela ne fonctionne que sur des plateformes cloud support√©es. GCP, AWS et Azure sont d√©finitivement support√©s. Si vous d√©finissez le type de service en tant que LoadBalancer dans un environnement non support√© comme VirtualBox ou d'autres environnements, cela aura le m√™me effet que de le d√©finir en tant que NodePort, o√π les services sont expos√©s sur un port √©lev√© sur les n≈ìuds. Il n'y aura simplement pas de configuration de load balancer externe.

- Lorsque nous passerons en revue les d√©monstrations de d√©ploiement de notre application sur des plateformes cloud, nous verrons cela en action.



